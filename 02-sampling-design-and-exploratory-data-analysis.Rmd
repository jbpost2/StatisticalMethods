# Sampling, Experiments, and Exploratory Data Analysis 

<!-- General Chapter Structure -->
<!-- - Motivating Problem/Problem Idea/What Data to Try to Collect -->
<!-- - Explanation of what a good model might be (or maybe this goes in with the data to try and collect?) -->
<!-- - EDA to explore and further motivate new topic -->
<!-- - Background needed for the model/inference -->
<!-- - Culmination of intro example -->
<!-- - Second example to put it all together -->
<!-- - Resources for when shit hits the fan -->

<!-- Alternative: -->
<!-- - Define the objective of the experiment -->
<!-- - Select appropriate response variables -->
<!-- - Identify sources of variation -->
<!-- - Choose experimental design -->
<!-- - Perform the test -->
<!-- - Statistically analyze the data -->
<!-- - Draw conclusions -->



## Data in the Wild  

Data is a collection of information about a group, which may include both quantitative and qualitative variables.  Data is ubiquitous in today's society.  Healthcare, marketing, history, biology, ... basically every field has a quantitative aspect.  The quality of data varies greatly from study to study.  


### Data from Experiments  

Some data comes from a well-designed experiment where a researcher uses sound principles to select units and conduct interventions.  

For example, a mechanical engineer wants to determine which variables influence overall gas mileage of a certain year and model of a car.  Gas mileage would be referred to as the **response** variable for this study.  

After careful consideration, the engineer chooses to investigate the following **factors** that may affect the overall gas mileage:  

- Tire pressure (low, standard)  
- Octane rating of fuel (regular, midgrade, premium)  
- Type of driving (defensive, aggressive)

They also choose to **control** or hold constant the following variables during the implementation of the study:  

- Weather conditions  
- Route  
- Tire type  
- Past car usage

The engineer randomly selects 24 cars from the assembly line for that year and model of car (we'll learn more about the importance of selecting a representative sample of cars shortly).  Software is used to randomly assign a **treatment** or combination of the factors to each car of the 24 cars.  For instance, low tire pressure, regulare octane fuel, and defensive driving would be a treatement.  The cars would be called the **experimental units** or (EUs) as they are the unit the treatments are assigned to.  

The experiment is run and the gas mileage found for each car.  As the car is being measured we'd refer to the car as the **observational unit**.

This short description exhibits three important concepts in experimental design that we'll come back to many times.  
  

```{block2, type = 'definition'}

Experiment - researchers manipulate the conditions in which the study is done.  

```

Pillars of experimental design:  

 - Randomization - treatments are randomly assigned to the experimental units   
 - Replication - multiple (independent) experimental units are assigned the same treatment  
 - Control - study conditions are held constant where possible to reduce variability in the response    


### Data from Observational Studies  

Other data comes from observations studies where ...  For example, ... 

<<call out with observational study>>
 
The implications for the conclusions that can be made from a set of data varies greatly with the quality of the data and study design.

<<call out with conclusions table>>

Both studies have some things in common - popu sample...
 
Statistics is the science of learning from data.  (Other definition from some book but not sure which - the science of designing studies or experiments, collecting data and modeling/analyzing data for the purpose of decisions making and scientific discovery when the available information is both limited and variable.)

<<call out about statistics, general usage vs this type of definition>>

Statistical methods are needed because data is variable.  For example... The full statistical process begins with ... 
- Define the objective of the experiment  
- Select appropriate response variables   
- Identify sources of variation   
- Choose experimental design  
- Perform the test  
- Statistically analyze the data  
- Draw conclusions  

We'll focus on the entire process of a study and mostly investigate designed experiments.  We attempt to tackle each topioc in this text with a problem-based approach.  That is, we identify a real-world problem and discuss the relevant statistical ideas in context.  Summaries at the end of each chapter recap the main statistical ideas.  

### Experiment Background  

Marketing example.  Goal to describe the customers, how they tend to purchase/shop, and maybe find some shared qualities in order to adverstise curated packages to folks.

Define basic things like population, parameters, statistics, and sample.

Discuss conceptual vs actual populations and when we might care about one or the other.  Our "sample" is really a bit of data from the conceptual population.  Or we could consider it as the population and we just want to describe it. 

### Selecting Response Variables

Marketing example with data such as Clicks, Impressions, Total Revenue, Total Spent, Average Order Value, Sport, Time of visit/purchase, Campaigns running, etc.

### Identifying Sources of Variation 

Consider variables linked to the user.  Age, other accounts, etc.  

### Choose an Experimental Design <!-- Is this intended to include any sampling considerations?-->

Discuss our "sampling" scheme vs a random sample.  This seems like a case where we aren't doing a "good" scheme but not much else could be done...  

Maybe talk about how in the future you could do alternate email ads or something and do an AB type study.


### Peform the Test  <!-- Wait, does this mean to actually execute the experiment? -->

Get the data from google analytics or whatever, have a plan for updating each month?

### Look at the Data  <!-- I think we need to add this as a much needed step!  If nothing else than for data validation.  I'm assuming perform the test now means collect the data. Perhaps this could fall into the Statistically analyze the data part though... Might be good to separate out the exploring/validating part though.  -->

Careful discussion of not selecting a modeling technique based on this unless it is a pilot study or an exploratory study else we have increased our nominal type I error rate... 

(sometimes EDA sometimes data validation only/cleaning - more formal experiments)

Spend a lot of time here talking about graphs of different types.  Sample means, sample variances, etc.

Discuss population curves vs sample histograms and the relationship.

### Statistically Analyze the Data  

New variables as functions of old?

Not a formal test here but comparisons of interest etc.

### Draw conclusions

What actionable things have we found?  Likely some trends to investigate further.  Perhaps run an experiment to formally see if some alteration can be effective.  

What can we conclude realistically from this data?  To what population are we talking?  


## Statistical Testing Ideas  

### Experiment Background 

This example would lend itself to a reasonably easy randomization test or simulation based test.  Maybe an AB type study where we swap labels and do that with a nice visual.

Maybe third example with simulation test.

### Selecting Response Variables


### Identifying Sources of Variation 


### Choose an Experimental Design 

Good discussion of what makes a good sampling design.  Maybe a statified example like the river and selecting houses example as a quick expose of the issues with not doing a truly random sampling technique.

Basics of experimental design (randomization, replication, error control ideas).

Recap benefits of doing an experiment vs an observational study.

### Peform the Test  

### Explore the Data  

NHST paradigm with false discovery?

### Statistically Analyze the Data  


### Draw conclusions

<!-- - Frame still with question of interest.  Maybe pilot study or study where we mainly care about summary stats.
 - How does data look in the wild and how do we deal with it in the wild.  How could it be modeled via distributions?  Sample representing the larger group.
 - Not too much math here, save that for later mostly.
 - Simulation/Randomization based hypothesis testing. 
. 
.
Thoughts:
Inference ideas - pop, sample, etc.
how we get our units important
  SRS
Good vs bad sampling and the traits
experiment ideas/fundamentals
  CRD
can do experiment or observational
conclusions to make from those (matrix of things)
.
Sample of Random Variable's realizations, sample distribution vs populaton, modeling ideas
Approx probabilities and quantiles vs theoretical
Summaries of distributions (center, spread, graphs)
.
Components of a research study or maybe the general process of a research study
Things to do before and after data collection
Real vs conceptual populations (finite vs infinite)
-->
