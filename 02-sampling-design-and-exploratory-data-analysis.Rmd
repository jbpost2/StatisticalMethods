# Sampling, Experiments, and Exploratory Data Analysis 

## Data in the Wild  

Data is a collection of information about a group, which may include both quantitative and qualitative variables.  Data is ubiquitous in today's society.  Healthcare, marketing, history, biology, ... basically every field has a quantitative aspect.  The quality of data varies greatly from study to study.  


### Data from Experiments  

Some data comes from a well-designed experiment where a researcher uses sound principles to select units and conduct interventions.  

For example, a mechanical engineer wants to determine which variables influence overall gas mileage of a certain year and model of a car.  Gas mileage would be referred to as the **response** variable for this study.  

After careful consideration, the engineer chooses to investigate a few **explanatory variables**.  They looked at the following **factors** that they believed may affect the overall gas mileage:  

- Tire pressure (low, standard)  
- Octane rating of fuel (regular, midgrade, premium)  
- Type of driving (defensive, aggressive)

They also choose to **control** or hold constant the following variables during the implementation of the study:  

- Weather conditions  
- Route  
- Tire type  
- Past car usage

The engineer randomly selects 24 cars from the assembly line for that year and model of car (we'll learn more about the importance of selecting a representative sample of cars shortly).  Software is used to randomly assign a **treatment** or combination of the factors to each car of the 24 cars.  For instance, low tire pressure, regulare octane fuel, and defensive driving would be a treatement.  The cars would be called the **experimental units** or (EUs) as they are the unit the treatments are assigned to.  

The experiment is run and the gas mileage found for each car.  As the car is being measured we'd refer to the car as the **observational unit**.

This short description exhibits three important concepts in experimental design that we'll come back to many times.  
  

```{block2, type = 'definition'}

Experimental Study - researchers manipulate the conditions in which the study is done.  

```



Pillars of experimental design: (Put an outer block around this)   

```{block2, type = 'definition'}

 - Randomization - treatments are randomly assigned to the experimental units   

```
```{block2, type = 'definition'}

 - Replication - multiple (independent) experimental units are assigned the same treatment  

```
```{block2, type = 'definition'}

 - Control - study conditions are held constant where possible to reduce variability in the response    

```


### Data from Observational Studies  

Some data comes from an observational study where the researcher collects data without imposing any changes.   

For example, an economist wants to investigate the effects of recently added tariffs on agricultural products to the amount and value of such products that are traded between the United States and Asia.  This study would have two **response** variables, amount and value of each product traded between the two parties.  

In order to take into account season variation and time of year, the economist decides to compare the two response variables from the current year - 6 months worth of data - to the *average* values of the two response variables during the same 6 month periods for the past 5 years.  We would refer to the time frame of the data as an **explanatory variable**.  This time frame could be labeled to take on one of two values: no-tariff (past) or tariff (current).  

The researcher obtains the data from the census bureau and conducts their analysis.  

Notice that the researcher, while certainly being actively involved in the careful consideration of the data to be collected, does not actively intervene or impose a change.  This is the key component of an observational study.  

```{block2, type = 'definition'}

Observational Study - researchers collects data without imposing any changes on the study environment.     

```


### Observational vs Experimental  

You may have noticed that both types of studies have some things in common.  For instance, both studies have **response** (??? so I was thinking about maybe bolding most stats words as we go to point them out to students... thoughts???) variables that characterizes the performance of the study in some sense.  Importantly, these response variables have variation.  That is, observing the variable is non-deterministic even under identical situations.  There are also **explanatory variables** that the researcher is interested in with regard to their relationship with the response variable.  

Beyond that, both studies hope to make conclusions about a larger group using data.  This is the idea of **statistical inference** (??? Do we want to talk about the differences between prediction and inference here? - later???).  More formally the group of values, items, or individuals defines the a **population** of interest and the data collected represents the **sample**.  For the gas mileage example, the population would be all cars of the year and make in question and the sample would be the data on the 24 cars.  For the tariff example, the population would be a **conceptual population** of all future agricultural products traded between the United States and Asia and the sample would be the information from the six years of trade data.   

```{block2, type = "definition"}

Population - (Possibly conceptual) group of units of interest  

```
```{block2, type = "definition"}

Sample - Subset of the population on which we observe data  

```
```{block2, type = "definition"}

Statistical Inference - Process of using sample data to make statements or claims about a population (???Usually with the goal of determing which variables are important for a response???)  

```

Both of these studies had to determine how to obtain their observations.  For the experiment, 24 cars were used.  For the observational study, six years of data were collected.  How this data is collected can be extremely important in terms of the types of conclusions that can be made.  Data needs to be **unbiased** and **representative** of the population in which the researcher hopes to make inference otherwise the conclusions made are likely invalid.  We'll discuss the idea of what makes a good and bad **sampling scheme** later. 

The major difference between the two studies was the active (experimental) and passive (observational) roles played by the researcher.  This difference is also of vital importance to the types of conclusions that can be made from the study.  A well-designed experiment can often infer causation to the treatments where an observational study cannot.  

The conclusions a researcher can make based on how the data were collected and the type of study are outlined in the table below.  (??? Probably just remake this table ourselves with our own words.  This isn't exactly 'their' original thought or something we need to attribute. ???)

```{r scopeTable, out.width="650px", fig.cap="Scope of Inference, cite: Khan Academy", echo = FALSE}
knitr::include_graphics("img/ScopeOfInferenceTable.png")
```

Doing an observational study doesn't mean that your study is bad!  An observational study is sometimes done out of necessity when an experiment wouldn't be ethical or feasible.  For the tariff example, there really isn't a way to conduct an experiment.  If we wanted to design an experiment to see if smoking causes lung cancer, that would be unethical because we can't force people to smoke.  The key point is that the implications we can draw will differ greatly between experimental and observational studies and will depend heavily on the quality (in relation to the population) of the data you have.   


### The Role of Statistics  
 
Statistics is the science of learning from data.  It encompasses the collection of data, the design of an experiment, the summarization of data, and the modeling or analysis used in order to make a decision or further scientific knowledge. (???I feel like this definition doesn't quite get the sampling part right or maybe the holistic process or something - update as needed! JP???)  

```{block2, type = "definition"}
(This will be changed to a different style of callout - maybe "note"?)

Statistics in every day use usually refers to simply summaries about data (means/averages, proportions, or counts).  

Statistics as a field encompasses a much larger range of ideas including how to collect data, model data, and make decisions or come to conclusions when faced with uncertainty.  

```

**Statistical methods are needed because data is variable.**  If we again collected data about the gas mileage of vehicles under the exact same study conditions we'll get slightly different results.  If we observed another six month period of trade data we'll see different amounts and values.  Accounting for this variability in data is a key component of a statistical analysis.   

Generally, one should try to take a holistic view of a study.  Before any data is collected it is vital to understand the goals and background of the study.  These will inform the data you ideally want to collect as well as the data that you are able to collect - which may need to act as a proxy.  A plan should be determined for the actual collection and storing of the data.  The entire study design will then inform the statistical analysis and conclusions that can be drawn.  

Taking this bigger picture view of the problem, we can usually follow these steps (we'll try to follow these throughout the book!):  

- Define the objective of the experiment and understand the background (Objective & Background)    
- Select appropriate response variables (Response)  
- Identify sources of variation (Sources of Variation)  
- Choose experimental design (if applicable) (Experimental Design)  
- Perform the test/collect the data (??? not sure how to shorten that to make it make sense ???) 
- Statistically analyze the data (Analysis)  
- Draw conclusions (Conclusions)  

We'll focus on this entire process and mostly investigate designed experiments.  We attempt to tackle each topic in this text with a problem-based approach.  That is, we identify a real-world problem and discuss the relevant statistical ideas in context.  Summaries at the end of each chapter recap the main statistical ideas and discuss other important related topics.  


## Observational Study - Farmer's Market   

### Experiment Background  

An agricultural **something...** wanted to characterize the vendors at the North Carolina State Farmer's Market (henceforth the farmer's market) in order to learn about their sales and knowledge of food hygiene and safety.  The researcher had access to the names of each vendor's business and their general purpose.  There were xxx types of businesses selling xxx.

The researcher needed to decide the scope of their study.  Formally, they needed to define the **population** of interest.  The population is the group of people or units of interest to the researcher.  In this case the population was all of the vendor's at the farmer's market other than the restaurants.  One could try to do a study at just the North Carolina State Farmer's Market and extend the results to all farmer's market in the state or in the south, but that would require many assumptions to be valid.  

```{block2, type = "definition"}

Population - group of people or units of interest  

```

### Selecting Response Variables

The researchers needed to determine the variables to collect that would best help to answer their questions of interest.  These variables that characterize the experiment are called **response** or target variables.  They decided to collect vendors sales by looking at the (AMT) amount sold per week over the past two years (in dollars), the (UN_ITEMS) number of unique items sold per week over the past two years, and the (NUM_ITEMS) total number of items sold per week over the past two years.  For the last variable they had to decide how to measure the number of items sold for the different types of businesses.  For produce they decided to collect the total weight (in lbs) sold, for the live plant selling ... 

To investigate the knowledge of hygiene and safety, a short questionnaire was developed to allow the vendor's head manager (or similar employee) to self evaluate as well as answer some general questions developed around proper policy.  

You can see that there are many decisions that the researcher must make in simply deciding the response variables to collect!  A poor choice here can make or break a study.

(Maybe mention observational unit here as well.)

### Identifying Sources of Variation 

The response variables clearly have some relationship to other variables that could be collected.  For instance, the NUM_ITEMS variable is clearly going to be different for the different types of vendors.  The AMT variable would differ depending on the size of the vendor's inventory.  These are examples of **explanatory variables** or variables that define the study conditions.  Explanatory variables go by many names such as predictors, features, or independent variables.  

A main consideration about whether or not to record a variable is whether or not the variable would be related to a variation in the response.  Since the response variables are truly what is of interest, there is really not much of a point in recording variables that likely have no relationship with it.  

Choosing the explanatory variables also can indicate further questions of interest.  We may want to compare the average AMT for ... leading to a comparison across groups being of interest.  This average amount would be referred to as a parameter of interest.  A **parameter** is a summary measure about a population.  Common parameters investigated include the mean, variance, or median of a different subgroups of the overall population.  

### Choose an Experimental Design <!-- Is this intended to include any sampling considerations?-->

For this study the researchers aren't interested in doing an interavention so an observational study was being done.  The major task to consider for the observational study is how to select participants from the population.  The subset of the population we (attempt to) observe our data on is called the **sample**.  

```{block2, type = "definition"}

Sample - subset of the population we observe our data on

```

Ideally we would measure every member of our population.  This is called a **census**.  Conducting a census can be extremely costly or time instensive.  It a census can be done then values of a population's parameters can be found exactly by simply summarizing the population data.  

Most of the time a census cannot be done.  This means that the information we collect would likely be different if we collected it again.  This variability is really the main reason statistical analysis is needed.  

How the researcher selects their sample is extremely important.  The sample should be **unbiased** and **respresentative** of the population.  

(Explain those terms)

There are many good ways to select the sample and many bad ways.  (Talk about bad first and why bad - visuals too)  Talk about good and why good - visuals too.


### Peform the Test  <!-- Wait, does this mean to actually execute the experiment? -->

Get the data from google analytics or whatever, have a plan for updating each month?

### Look at the Data  <!-- I think we need to add this as a much needed step!  If nothing else than for data validation.  I'm assuming perform the test now means collect the data. Perhaps this could fall into the Statistically analyze the data part though... Might be good to separate out the exploring/validating part though.  -->

Careful discussion of not selecting a modeling technique based on this unless it is a pilot study or an exploratory study else we have increased our nominal type I error rate... 

(sometimes EDA sometimes data validation only/cleaning - more formal experiments)

Spend a lot of time here talking about graphs of different types.  Sample means, sample variances, etc.

Discuss population curves vs sample histograms and the relationship.

### Statistically Analyze the Data  

New variables as functions of old?

Not a formal test here but comparisons of interest etc.

### Draw conclusions

What actionable things have we found?  Likely some trends to investigate further.  Perhaps run an experiment to formally see if some alteration can be effective.  

What can we conclude realistically from this data?  To what population are we talking?  


## Statistical Testing Ideas  

### Experiment Background 

This example would lend itself to a reasonably easy randomization test or simulation based test.  Maybe an AB type study where we swap labels and do that with a nice visual.

Maybe third example with simulation test.

### Selecting Response Variables


### Identifying Sources of Variation 


### Choose an Experimental Design 

Good discussion of what makes a good sampling design.  Maybe a statified example like the river and selecting houses example as a quick expose of the issues with not doing a truly random sampling technique.

Basics of experimental design (randomization, replication, error control ideas).

Recap benefits of doing an experiment vs an observational study.

### Peform the Test  

### Explore the Data  

NHST paradigm with false discovery?

### Statistically Analyze the Data  


### Draw conclusions



The implications for the conclusions that can be made from a set of data varies greatly with the quality of the data and study design.  


<!-- - Frame still with question of interest.  Maybe pilot study or study where we mainly care about summary stats.
 - How does data look in the wild and how do we deal with it in the wild.  How could it be modeled via distributions?  Sample representing the larger group.
 - Not too much math here, save that for later mostly.
 - Simulation/Randomization based hypothesis testing. 
. 
.
Thoughts:
Inference ideas - pop, sample, etc.
how we get our units important
  SRS
Good vs bad sampling and the traits
experiment ideas/fundamentals
  CRD
can do experiment or observational
conclusions to make from those (matrix of things)
.
Sample of Random Variable's realizations, sample distribution vs populaton, modeling ideas
Approx probabilities and quantiles vs theoretical
Summaries of distributions (center, spread, graphs)
.
Components of a research study or maybe the general process of a research study
Things to do before and after data collection
Real vs conceptual populations (finite vs infinite)
-->
