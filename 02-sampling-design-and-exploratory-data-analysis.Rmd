# Sampling, Experiments, and Exploratory Data Analysis 

<!-- General Chapter Structure -->
<!-- - Motivating Problem/Problem Idea/What Data to Try to Collect -->
<!-- - Explanation of what a good model might be (or maybe this goes in with the data to try and collect?) -->
<!-- - EDA to explore and further motivate new topic -->
<!-- - Background needed for the model/inference -->
<!-- - Culmination of intro example -->
<!-- - Second example to put it all together -->
<!-- - Resources for when shit hits the fan -->

<!-- Alternative: -->
<!-- - Define the objective of the experiment -->
<!-- - Select appropriate response variables -->
<!-- - Identify sources of variation -->
<!-- - Choose experimental design -->
<!-- - Perform the test -->
<!-- - Statistically analyze the data -->
<!-- - Draw conclusions -->



## Data in the Wild  

Data is a collection of information about a group, which may include both quantitative and qualitative variables.  Data is ubiquitous in today's society.  Healthcare, marketing, history, biology, ... basically every field has a quantitative aspect.  The quality of data varies greatly from study to study.  


### Data from Experiments  

Some data comes from a well-designed experiment where a researcher uses sound principles to select units and conduct interventions.  

For example, a mechanical engineer wants to determine which variables influence overall gas mileage of a certain year and model of a car.  Gas mileage would be referred to as the **response** variable for this study.  

After careful consideration, the engineer chooses to investigate a few **explanatory variables**.  They looked at the following **factors** that they believed may affect the overall gas mileage:  

- Tire pressure (low, standard)  
- Octane rating of fuel (regular, midgrade, premium)  
- Type of driving (defensive, aggressive)

They also choose to **control** or hold constant the following variables during the implementation of the study:  

- Weather conditions  
- Route  
- Tire type  
- Past car usage

The engineer randomly selects 24 cars from the assembly line for that year and model of car (we'll learn more about the importance of selecting a representative sample of cars shortly).  Software is used to randomly assign a **treatment** or combination of the factors to each car of the 24 cars.  For instance, low tire pressure, regulare octane fuel, and defensive driving would be a treatement.  The cars would be called the **experimental units** or (EUs) as they are the unit the treatments are assigned to.  

The experiment is run and the gas mileage found for each car.  As the car is being measured we'd refer to the car as the **observational unit**.

This short description exhibits three important concepts in experimental design that we'll come back to many times.  
  

```{block2, type = 'definition'}

Experimental Study - researchers manipulate the conditions in which the study is done.  

```



Pillars of experimental design: (Put an outer block around this)   

```{block2, type = 'definition'}

 - Randomization - treatments are randomly assigned to the experimental units   

```
```{block2, type = 'definition'}

 - Replication - multiple (independent) experimental units are assigned the same treatment  

```
```{block2, type = 'definition'}

 - Control - study conditions are held constant where possible to reduce variability in the response    

```


### Data from Observational Studies  

Some data comes from an observational study where the researcher collects data without imposing any changes.   

For example, an economist wants to investigate the effects of recently added tariffs on agricultural products to the amount and value of such products that are traded between the United States and Asia.  This study would have two **response** variables, amount and value of each product traded between the two parties.  

In order to take into account season variation and time of year, the economist decides to compare the two response variables from the current year - 6 months worth of data - to the *average* values of the two response variables during the same 6 month periods for the past 5 years.  We would refer to the time frame of the data as an **explanatory variable**.  This time frame could be labeled to take on one of two values: no-tariff (past) or tariff (current).  

The researcher obtains the data from the census bureau and conducts their analysis.  

Notice that the researcher, while certainly being actively involved in the careful consideration of the data to be collected, does not actively intervene or impose a change.  This is the key component of an observational study.  

```{block2, type = 'definition'}

Observational Study - researchers collects data without imposing any changes on the study environment.     

```


### Observational vs Experimental  

You may have noticed that both types of studies have some things in common.  For instance, both studies have **response** (??? so I was thinking about maybe bolding most stats words as we go to point them out to students... thoughts???) variables that characterizes the performance of the study in some sense.  Importantly, these response variables have variation.  That is, observing the variable is non-deterministic even under identical situations.  There are also **explanatory variables** that the researcher is interested in with regard to their relationship with the response variable.  

Beyond that, both studies hope to make conclusions about a larger group using data.  This is the idea of **statistical inference** (??? Do we want to talk about the differences between prediction and inference here? - later???).  More formally the group of values, items, or individuals defines the a **population** of interest and the data collected represents the **sample**.  For the gas mileage example, the population would be all cars of the year and make in question and the sample would be the data on the 24 cars.  For the tariff example, the population would be a **conceptual population** of all future agricultural products traded between the United States and Asia and the sample would be the information from the six years of trade data.   

```{block2, type = "definition"}

Population - Group of units of interest  

```
```{block2, type = "definition"}

Sample - Subset of the population on which we observe data  

```
```{block2, type = "definition"}

Statistical Inference - Process of using sample data to make statements or claims about a population (???Usually with the goal of determing which variables are important for a response???)  

```


Sampling scheme
Random assignment and its importance


The major difference is of course 

The implications for the conclusions that can be made from a set of data varies greatly with the quality of the data and study design.

```{r scopeTable, out.width="650px", fig.cap="Scope of Inference, cite: Khan Academy", echo = FALSE}
knitr::include_graphics("img/ScopeOfInferenceTable.png")
```

Doing an observational study doesn't mean that your study is bad!  An observational study is sometimes done out of necessity when an experiment wouldn't be ethical or feasible.  For the tariff example, there really isn't a way to conduct an experiment.  If we wanted to design an experiment to see if smoking causes lung cancer, that would be unethical because we can't force people to smoke.  The key point is that the implications we can draw will differ greatly between experimental and observational studies.   


### The Role of Statistics  
 
Statistics is the science of learning from data.  It encompasses the collection of data, the design of an experiment, the summarization of data, and the modeling or analysis used in order to make a decision or further scientific knowledge. (???I feel like this definition doesn't quite get the sampling part right or maybe the holistic process or something - update as needed! JP???)  

```{block2, type = "definition"}
(This will be changed to a different style of callout - maybe "note"?)

Statistics in every day use usually refers to simply summaries about data (means/averages, proportions, or counts).  

Statistics as a field encompasses a much larger range of ideas including how to collect data, model data, and make decisions or come to conclusions when faced with uncertainty.  

```

**Statistical methods are needed because data is variable.**  If we again collected data about the gas mileage of vehicles under the exact same study conditions we'll get slightly different results.  If we observed another six month period of trade data we'll see different amounts and values.  Accounting for this variability in data is a key component of a statistical analysis.   

Generally, one should try to take a holistic view of a study.  Before any data is collected it is vital to understand the goals and background of the study.  These will inform the data you ideally want to collect as well as the data that you are able to collect - which may need to act as a proxy.  A plan should be determined for the actual collection and storing of the data.  The entire study design will then inform the statistical analysis and conclusions that can be drawn.  

Taking this bigger picture view of the problem, we can usually follow these steps (we'll try to follow these throughout the book!):  

- Define the objective of the experiment and understand the background (Objective & Background)    
- Select appropriate response variables (Response)  
- Identify sources of variation (Sources of Variation)  
- Choose experimental design (if applicable) (Experimental Design)  
- Perform the test/collect the data (??? not sure how to shorten that to make it make sense ???) 
- Statistically analyze the data (Analysis)  
- Draw conclusions (Conclusions)  

We'll focus on this entire process and mostly investigate designed experiments.  We attempt to tackle each topic in this text with a problem-based approach.  That is, we identify a real-world problem and discuss the relevant statistical ideas in context.  Summaries at the end of each chapter recap the main statistical ideas.  


## Marketing Example  

### Experiment Background  

Marketing example.  Goal to describe the customers, how they tend to purchase/shop, and maybe find some shared qualities in order to adverstise curated packages to folks.

Define basic things like population, parameters, statistics, and sample.

Discuss conceptual vs actual populations and when we might care about one or the other.  Our "sample" is really a bit of data from the conceptual population.  Or we could consider it as the population and we just want to describe it. 

### Selecting Response Variables

Marketing example with data such as Clicks, Impressions, Total Revenue, Total Spent, Average Order Value, Sport, Time of visit/purchase, Campaigns running, etc.

### Identifying Sources of Variation 

Consider variables linked to the user.  Age, other accounts, etc.  

### Choose an Experimental Design <!-- Is this intended to include any sampling considerations?-->

Discuss our "sampling" scheme vs a random sample.  This seems like a case where we aren't doing a "good" scheme but not much else could be done...  

Maybe talk about how in the future you could do alternate email ads or something and do an AB type study.


### Peform the Test  <!-- Wait, does this mean to actually execute the experiment? -->

Get the data from google analytics or whatever, have a plan for updating each month?

### Look at the Data  <!-- I think we need to add this as a much needed step!  If nothing else than for data validation.  I'm assuming perform the test now means collect the data. Perhaps this could fall into the Statistically analyze the data part though... Might be good to separate out the exploring/validating part though.  -->

Careful discussion of not selecting a modeling technique based on this unless it is a pilot study or an exploratory study else we have increased our nominal type I error rate... 

(sometimes EDA sometimes data validation only/cleaning - more formal experiments)

Spend a lot of time here talking about graphs of different types.  Sample means, sample variances, etc.

Discuss population curves vs sample histograms and the relationship.

### Statistically Analyze the Data  

New variables as functions of old?

Not a formal test here but comparisons of interest etc.

### Draw conclusions

What actionable things have we found?  Likely some trends to investigate further.  Perhaps run an experiment to formally see if some alteration can be effective.  

What can we conclude realistically from this data?  To what population are we talking?  


## Statistical Testing Ideas  

### Experiment Background 

This example would lend itself to a reasonably easy randomization test or simulation based test.  Maybe an AB type study where we swap labels and do that with a nice visual.

Maybe third example with simulation test.

### Selecting Response Variables


### Identifying Sources of Variation 


### Choose an Experimental Design 

Good discussion of what makes a good sampling design.  Maybe a statified example like the river and selecting houses example as a quick expose of the issues with not doing a truly random sampling technique.

Basics of experimental design (randomization, replication, error control ideas).

Recap benefits of doing an experiment vs an observational study.

### Peform the Test  

### Explore the Data  

NHST paradigm with false discovery?

### Statistically Analyze the Data  


### Draw conclusions

<!-- - Frame still with question of interest.  Maybe pilot study or study where we mainly care about summary stats.
 - How does data look in the wild and how do we deal with it in the wild.  How could it be modeled via distributions?  Sample representing the larger group.
 - Not too much math here, save that for later mostly.
 - Simulation/Randomization based hypothesis testing. 
. 
.
Thoughts:
Inference ideas - pop, sample, etc.
how we get our units important
  SRS
Good vs bad sampling and the traits
experiment ideas/fundamentals
  CRD
can do experiment or observational
conclusions to make from those (matrix of things)
.
Sample of Random Variable's realizations, sample distribution vs populaton, modeling ideas
Approx probabilities and quantiles vs theoretical
Summaries of distributions (center, spread, graphs)
.
Components of a research study or maybe the general process of a research study
Things to do before and after data collection
Real vs conceptual populations (finite vs infinite)
-->
