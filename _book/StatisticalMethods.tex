\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={A Minimal Book Example},
  pdfauthor={Yihui Xie},
  pdfborder={0 0 0},
  breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{A Minimal Book Example}
\author{Yihui Xie}
\date{2020-01-22}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{prerequisites}{%
\chapter{Prerequisites}\label{prerequisites}}

Stuff

\hypertarget{sampling-experiments-and-exploratory-data-analysis}{%
\chapter{Sampling, Experiments, and Exploratory Data Analysis}\label{sampling-experiments-and-exploratory-data-analysis}}

\hypertarget{data-in-the-wild}{%
\section{Data in the Wild}\label{data-in-the-wild}}

Data is a collection of information about a group, which may include both quantitative and qualitative variables. Data is ubiquitous in today's society. Healthcare, marketing, history, biology, \ldots{} basically every field has a quantitative aspect. The quality of data varies greatly from study to study.

\hypertarget{data-from-experiments}{%
\subsection{Data from Experiments}\label{data-from-experiments}}

Some data comes from a well-designed experiment where a researcher uses sound principles to select units and conduct interventions.

For example, a mechanical engineer wants to determine which variables influence overall gas mileage of a certain year and model of a car. Gas mileage would be referred to as the \textbf{response} variable for this study.

After careful consideration, the engineer chooses to investigate the following \textbf{factors} that may affect the overall gas mileage:

\begin{itemize}
\tightlist
\item
  Tire pressure (low, standard)\\
\item
  Octane rating of fuel (regular, midgrade, premium)\\
\item
  Type of driving (defensive, aggressive)
\end{itemize}

They also choose to \textbf{control} or hold constant the following variables during the implementation of the study:

\begin{itemize}
\tightlist
\item
  Weather conditions\\
\item
  Route\\
\item
  Tire type\\
\item
  Past car usage
\end{itemize}

The engineer randomly selects 24 cars from the assembly line for that year and model of car (we'll learn more about the importance of selecting a representative sample of cars shortly). Software is used to randomly assign a \textbf{treatment} or combination of the factors to each car of the 24 cars. For instance, low tire pressure, regulare octane fuel, and defensive driving would be a treatement. The cars would be called the \textbf{experimental units} or (EUs) as they are the unit the treatments are assigned to.

The experiment is run and the gas mileage found for each car. As the car is being measured we'd refer to the car as the \textbf{observational unit}.

This short description exhibits three important concepts in experimental design that we'll come back to many times.

\BeginKnitrBlock{definition}
Experimental Study - researchers manipulate the conditions in which the study is done.
\EndKnitrBlock{definition}

Pillars of experimental design: (Put an outer block around this)

\BeginKnitrBlock{definition}
\begin{itemize}
\tightlist
\item
  Randomization - treatments are randomly assigned to the experimental units\\
\end{itemize}
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}
\begin{itemize}
\tightlist
\item
  Replication - multiple (independent) experimental units are assigned the same treatment\\
\end{itemize}
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}
\begin{itemize}
\tightlist
\item
  Control - study conditions are held constant where possible to reduce variability in the response\\
\end{itemize}
\EndKnitrBlock{definition}

\hypertarget{data-from-observational-studies}{%
\subsection{Data from Observational Studies}\label{data-from-observational-studies}}

Some data comes from an observational study where the researcher collects data without imposing any changes.

For example, an economist wants to investigate the effects of recently added tariffs on agricultural products to the amount of and value of those products that are traded between the United States and Asia. This study would have two \textbf{response} variables, amount and value of each product traded between the two parties.

In order to take into account season variation and time of year, the economist decides to compare the two response variables from the current year - 6 months worth of data - to the \emph{average} values of the two response variables during the same 6 month periods for the past 5 years. We would refer to the time frame of the data as an \textbf{explanatory variable}. This time frame could be labeled to take on one of two values: no-tariff (past) or tariff (current).

The researcher obtains the data from the census bureau and conducts their analysis.

Notice that the researcher, while certainly being actively involved in the careful consideration of the data to be collected, does not actively intervene or impose a change. This is the key component of an observational study.

\BeginKnitrBlock{definition}
Observational Study - researchers collects data without imposing any changes on the study environment.
\EndKnitrBlock{definition}

\hypertarget{observational-vs-experimental-similarities-and-differences}{%
\subsection{Observational vs Experimental: Similarities and Differences}\label{observational-vs-experimental-similarities-and-differences}}

You may have noticed that both types of studies have some things in common. For instance,

Both studies have some things in common - popu sample\ldots{}

Doing an observational study doesn't mean that your study is bad! For the tariff example, there really isn't a way to conduct an experiment. The implications that we can draw will differ greatly between experiments and observational studies.

The implications for the conclusions that can be made from a set of data varies greatly with the quality of the data and study design.

Observational study is sometimes done out of necessity when an experiment wouldn't be ethical.

\textless{}\textgreater{}

\hypertarget{the-role-of-statistics}{%
\subsection{The Role of Statistics}\label{the-role-of-statistics}}

Statistics is the science of learning from data. It encompasses the collection of data, the design of an experiment, the summarization of data, and the modeling or analysis used in order to make a decision or further scientific knowledge. (???I feel like this definition doesn't quite get the sampling part right or maybe the holistic process or something - update as needed! JP???)

\BeginKnitrBlock{definition}
(This will be changed to a different style of callout - maybe ``note''?)

Statistics in every day use usually refers to simply summaries about data (means/averages, proportions, or counts).

Statistics as a field encompasses a much larger range of ideas including how to collect data, model data, and make decisions or come to conclusions when faced with uncertainty.
\EndKnitrBlock{definition}

\textbf{Statistical methods are needed because data is variable.} If we again collected data about the gas mileage of vehicles under the exact same study conditions we'll get slightly different results. If we observed another six month period of trade data we'll see different amounts and values. Accounting for this variability in data is a key component of a statistical analysis.

Generally, one should try to take a holistic view of a study. Before any data is collected it is vital to understand the goals and background of the study. These will inform the data you ideally want to collect as well as the data that you are able to collect - which may need to act as a proxy. A plan should be determined for the actual collection and storing of the data. The entire study design will then inform the statistical analysis and conclusions that can be drawn.

Taking this bigger picture view of the problem, we can usually follow these steps (we'll try to follow these throughout the book!):

\begin{itemize}
\tightlist
\item
  Define the objective of the experiment and understand the background (Objective \& Background)\\
\item
  Select appropriate response variables (Response)\\
\item
  Identify sources of variation (Sources of Variation)\\
\item
  Choose experimental design (if applicable) (Experimental Design)\\
\item
  Perform the test/collect the data (??? not sure how to shorten that to make it make sense ???)
\item
  Statistically analyze the data (Analysis)\\
\item
  Draw conclusions (Conclusions)
\end{itemize}

We'll focus on this entire process and mostly investigate designed experiments. We attempt to tackle each topic in this text with a problem-based approach. That is, we identify a real-world problem and discuss the relevant statistical ideas in context. Summaries at the end of each chapter recap the main statistical ideas.

\hypertarget{marketing-example}{%
\section{Marketing Example}\label{marketing-example}}

\hypertarget{experiment-background}{%
\subsection{Experiment Background}\label{experiment-background}}

Marketing example. Goal to describe the customers, how they tend to purchase/shop, and maybe find some shared qualities in order to adverstise curated packages to folks.

Define basic things like population, parameters, statistics, and sample.

Discuss conceptual vs actual populations and when we might care about one or the other. Our ``sample'' is really a bit of data from the conceptual population. Or we could consider it as the population and we just want to describe it.

\hypertarget{selecting-response-variables}{%
\subsection{Selecting Response Variables}\label{selecting-response-variables}}

Marketing example with data such as Clicks, Impressions, Total Revenue, Total Spent, Average Order Value, Sport, Time of visit/purchase, Campaigns running, etc.

\hypertarget{identifying-sources-of-variation}{%
\subsection{Identifying Sources of Variation}\label{identifying-sources-of-variation}}

Consider variables linked to the user. Age, other accounts, etc.

\hypertarget{choose-an-experimental-design}{%
\subsection{Choose an Experimental Design }\label{choose-an-experimental-design}}

Discuss our ``sampling'' scheme vs a random sample. This seems like a case where we aren't doing a ``good'' scheme but not much else could be done\ldots{}

Maybe talk about how in the future you could do alternate email ads or something and do an AB type study.

\hypertarget{peform-the-test}{%
\subsection{Peform the Test }\label{peform-the-test}}

Get the data from google analytics or whatever, have a plan for updating each month?

\hypertarget{look-at-the-data}{%
\subsection{Look at the Data }\label{look-at-the-data}}

Careful discussion of not selecting a modeling technique based on this unless it is a pilot study or an exploratory study else we have increased our nominal type I error rate\ldots{}

(sometimes EDA sometimes data validation only/cleaning - more formal experiments)

Spend a lot of time here talking about graphs of different types. Sample means, sample variances, etc.

Discuss population curves vs sample histograms and the relationship.

\hypertarget{statistically-analyze-the-data}{%
\subsection{Statistically Analyze the Data}\label{statistically-analyze-the-data}}

New variables as functions of old?

Not a formal test here but comparisons of interest etc.

\hypertarget{draw-conclusions}{%
\subsection{Draw conclusions}\label{draw-conclusions}}

What actionable things have we found? Likely some trends to investigate further. Perhaps run an experiment to formally see if some alteration can be effective.

What can we conclude realistically from this data? To what population are we talking?

\hypertarget{statistical-testing-ideas}{%
\section{Statistical Testing Ideas}\label{statistical-testing-ideas}}

\hypertarget{experiment-background-1}{%
\subsection{Experiment Background}\label{experiment-background-1}}

This example would lend itself to a reasonably easy randomization test or simulation based test. Maybe an AB type study where we swap labels and do that with a nice visual.

Maybe third example with simulation test.

\hypertarget{selecting-response-variables-1}{%
\subsection{Selecting Response Variables}\label{selecting-response-variables-1}}

\hypertarget{identifying-sources-of-variation-1}{%
\subsection{Identifying Sources of Variation}\label{identifying-sources-of-variation-1}}

\hypertarget{choose-an-experimental-design-1}{%
\subsection{Choose an Experimental Design}\label{choose-an-experimental-design-1}}

Good discussion of what makes a good sampling design. Maybe a statified example like the river and selecting houses example as a quick expose of the issues with not doing a truly random sampling technique.

Basics of experimental design (randomization, replication, error control ideas).

Recap benefits of doing an experiment vs an observational study.

\hypertarget{peform-the-test-1}{%
\subsection{Peform the Test}\label{peform-the-test-1}}

\hypertarget{explore-the-data}{%
\subsection{Explore the Data}\label{explore-the-data}}

NHST paradigm with false discovery?

\hypertarget{statistically-analyze-the-data-1}{%
\subsection{Statistically Analyze the Data}\label{statistically-analyze-the-data-1}}

\hypertarget{draw-conclusions-1}{%
\subsection{Draw conclusions}\label{draw-conclusions-1}}

\hypertarget{point-estimates}{%
\chapter{Point Estimates}\label{point-estimates}}

Learning objectives for this lesson:
- How to estimate a mean
- Definition of ``convenience sample''
- Definition of ``systematic sample''
- Benefits/drawbacks to both approaches
- Understand how to estimate a mean
- Understand how to estimate a quantile
- Understand implicit assumptions for these approaches

\hypertarget{estiamte-with-means}{%
\section{Estiamte with means}\label{estiamte-with-means}}

\hypertarget{experiment-background-2}{%
\subsection{Experiment background}\label{experiment-background-2}}

Someone wants to know how much of something they need to satisfy some population
To get a good estimate of this, we can use the average amount for each one and then multiply by the whole population

\hypertarget{estimate-with-quantiles}{%
\section{Estimate with quantiles}\label{estimate-with-quantiles}}

\hypertarget{experiment-background-3}{%
\subsection{Experiment background}\label{experiment-background-3}}

Big Deborah's is making new packaging for their cookies. The engineer responsible for the new desing needs to make sure that the packaging fits the new cookies. While the cookie manufacturing process is standardized, there's inevitably some degree of variation in cookie size. After discussing the issue with corporate, the engineer decides that a the new cookie sleeves should be large enough to fit 95\% of cookies that are baked. (The largest five percent will be marketed separately as ``JUMBO'' cookies.)

\hypertarget{define-the-object-of-the-experiment}{%
\subsection{Define the object of the experiment}\label{define-the-object-of-the-experiment}}

The Engineer is tasked with determining how large the cooke sleeve needs to be. There's no way for her to know the size of every cookie that Big Deborah's has made (or will make going forward!), so she'll need to collect data on existing cookies to inform her cookie sleeve size determination.

\hypertarget{select-appropriate-response-variables}{%
\subsection{Select appropriate response variables}\label{select-appropriate-response-variables}}

If the maximum distance from any one point on the (round) cookie's perimeter to any other point is smaller than the diameter of the cookie sleeve, then the cookie will fit. This makes ``cookie diameter'' a good measure for this test. It is easy to measure for each cookie and is directly relevant to the experiment's objective.

{[}probably have something in here about {]}

\hypertarget{identify-sources-of-variation}{%
\subsection{IDentify sources of variation}\label{identify-sources-of-variation}}

While the manufacturing process is standardized, there is variation in size from one cookie to the next. This is one source of variation. The engineer isn't sure of any others. However, she knows that cookies are made in multiple factories, and that each factory has multiple ovens. Ovens and factories could also be sources of variation.

\hypertarget{choose-an-experimental-design-2}{%
\subsection{Choose an experimental design}\label{choose-an-experimental-design-2}}

The Engineer knows that she needs to look at multiple cookies, since she knows that there is variation in diameter from one cookie to the next. One option would be to just use the remaining cookies in the box she has in her office (22 of the 25-count box remain). {[}something about convenience sample{]} However, she knows that cookies from the same oven are typically packaged together. If there is variation from one oven to the next, looking at the cookies she has in her office may not tell the whole story.

Instead, she chooses to take every 20th cookie manufactured off the assembly line until she gets 500 cookies. {[}something about systematic sample{]}

\hypertarget{perform-the-test}{%
\subsection{Perform the test}\label{perform-the-test}}

The day of the test comes, and the Engineer starts collecting cookies. However, problems arise! The plan has to shut down half-way through, so she only gets 431 cookies instead of the 500 she thought she would. However, she measures the diameters of each cookie and records the data in a spreadsheet.

\hypertarget{statistically-analyze-the-data-2}{%
\subsection{Statistically analyze the data}\label{statistically-analyze-the-data-2}}

The initial plan had been to rank-order the 500 cookies and estimate the 95th percentile using the diamter of the 475th largets cookie. Since we didn't get all of our data, we have to improvise. 431 doesn't neatly yield a value such that exactly 95\% are less than or equal and 5\% are greater than or equal. One option is to choose the 410th largest cookie to estimate our percentile. Slightly more than 95\% of cookies will have smaller diameters than this. Alternatively, we could interpolate between the 409th and 410th cookies. {[}reasons and logic and math for each of these{]}

\hypertarget{draw-conclusions-2}{%
\subsection{Draw conclusions}\label{draw-conclusions-2}}

Based on this study, the Engineer concludes that a cookie sleeve large enough for a cookie of diameter XX will be big enough to contain 95\% of Big Deborah cookies.

\hypertarget{discussion}{%
\subsection{Discussion}\label{discussion}}

\begin{itemize}
\tightlist
\item
  pros and cons to the approach chosen
\item
  generalizing to other types of point estimates
\end{itemize}

\hypertarget{accounting-for-uncertainty}{%
\chapter{Accounting for Uncertainty}\label{accounting-for-uncertainty}}

Some \emph{significant} applications are demonstrated in this chapter.

\hypertarget{example-one}{%
\section{Example one}\label{example-one}}

\hypertarget{example-two}{%
\section{Example two}\label{example-two}}

\hypertarget{HT}{%
\chapter{Inference via Hypothesis Tests for One Sample}\label{HT}}

We have finished a nice book.

\hypertarget{CI}{%
\chapter{Inference via Confidence Intervals for One Sample}\label{CI}}

We have finished a nice book.

\hypertarget{twocategorical}{%
\chapter{Inference for Two Categorical Variables}\label{twocategorical}}

We have finished a nice book.

\hypertarget{anova}{%
\chapter{One-Way ANOVA}\label{anova}}

Learning objectives for this lesson:
- Write one-way ANOVA model
- Define terms
- state assumptions
- interpret results
- Interpret ANOVA table
- Describe SSE, SST, MSE
- F-statistic
- degrees of freedom
- understand how all of these interrelate
- Understand how to compare mulitple group means how ANOVA is similar/different to t-tests
- Understand partitioning of variation and coefficient of determination

\hypertarget{motivating-example}{%
\chapter{Motivating example}\label{motivating-example}}

The United States Air Force Academy has 24 sections of Calculus I, taught by three different types of instructors: In-uniform instructors, full-time civilian instructors, and visiting faculty. The Dean of Students wants to give students the best experience possible and make sure that all three types of instructors are doing a good job. There are plausible reasons why any one of the three could be doing well: In-uniform instructors are all members of the Air Force, and students may be extra attention in these classes because they know that these instructors rank above them in their chain of command. On the other hand, full-time instructors have been aroudn the Academy for many years and understand the Cadets and their workloads. Alternatively, visiting facutly tend to come from prestigeous institutions and may be familiar with more recently-developed pedagogical techniques. Regardless, the Dean wants to understand if there is any variation in end-of-semester grades of classes taught by these three types of instructors. At the end of the semester, she collects the average grades from each of the 24 sections. How can she go about investigating this question?

Recall from Chapter 6 that we can use t-tests to compare two group means. In this case, we'd like to do a comparison across three groups, and instead of looking at a direct comparison of one group to another, what the Dean is interested in is whether there's an \emph{overall} difference across the three groups.

One option might be to just do a bunch of different t-tests. We could first compare classes taught by in-uniform instructors to classes taught by full-time civilians, then compare the classes taught by the in-uniform instructors to the classes taugth by the visiting instructors, and then finally compare the classes taugth by the full-time civilains with the classes taught by the visiting facutly. We'd end up with three p-values, each addressing different questions than the one we initially set out to answer.

We could do the same thing, except comparing courses taught by one type of instructor to the combined group of courses taught by the other two, and this gets a bit closer to the mark. But we're still doing three tests that individually fail to answer the Dean's question.

What we'd like instead is a single hypothesis that we could test that direclty gets at the Dean's concern about whether the three types of instructors were producing end-of-semester grades that were, on average, the same. {[}Need to make that motivation clearer above.{]}

\hypertarget{simple-model-for-the-data}{%
\chapter{Simple model for the data}\label{simple-model-for-the-data}}

Narrative explanation that instructor type might matter, there shold be some variation from class to class.
- write some things in greek, including model without any difference by instructor type
- wirte model with differences by instructor type
- note that we can use Gaussian errors b/c Academy grades do actually tend to be centered around a C, particularly for classes like Calc
- discuss model assumptions in general sense

\hypertarget{exploratory-analysis}{%
\chapter{exploratory analysis}\label{exploratory-analysis}}

\begin{itemize}
\tightlist
\item
  course-to-course variability is expected
\item
  maybe show a plot of it or something
\item
  visualize groups using box-and-whisker plots
\end{itemize}

\hypertarget{sources-of-variation}{%
\chapter{sources of variation}\label{sources-of-variation}}

Things like student population, time of day, etc. But we'll throw this all into an error term and focus on the main one, instructor type

\hypertarget{statistical-model-and-analysis}{%
\chapter{statistical model and analysis}\label{statistical-model-and-analysis}}

\begin{itemize}
\tightlist
\item
  ANVOA model explicit w/ assumptions
\item
  variation around overall mean w/ no groups
\item
  variation around group means
\item
  introduce idea of reference level
\end{itemize}

\hypertarget{compare-analyses}{%
\chapter{compare analyses}\label{compare-analyses}}

\begin{itemize}
\tightlist
\item
  t-test methods from above
\item
  ANOVA method
\item
  compare and contrast results, interpretations, etc.
\end{itemize}

\hypertarget{multiway}{%
\chapter{Multi-way ANOVA}\label{multiway}}

We have finished a nice book.

\hypertarget{block}{%
\chapter{Block Designs}\label{block}}

We have finished a nice book.

\hypertarget{regression}{%
\chapter{Regression Models}\label{regression}}

We have finished a nice book.

\hypertarget{glm}{%
\chapter{The General Linear Model}\label{glm}}

We have finished a nice book.

\hypertarget{mixedmodels}{%
\chapter{Mixed Models}\label{mixedmodels}}

We have finished a nice book.

\hypertarget{repeatedmeasures}{%
\chapter{Split Plot and Repeated Measures Designs}\label{repeatedmeasures}}

We have finished a nice book.

\hypertarget{logistic}{%
\chapter{Logistic Regression and Generalized Linear Models}\label{logistic}}

\hypertarget{stuff-here}{%
\section{Stuff here}\label{stuff-here}}

We have finished a nice book.

\hypertarget{glmm}{%
\chapter{Generalized Linear Mixed Models}\label{glmm}}

We have finished a nice book.

\hypertarget{learningobj}{%
\chapter{Appendix - Learning Objectives}\label{learningobj}}

\hypertarget{book-level}{%
\section{Book-level}\label{book-level}}

After reading this book you will be able to:

\begin{itemize}
\item
  identify relevent sources of variability for a potential study and, if applicable, utilize principles of design to plan a reasonable experiment to help answer questions of interest

  \begin{itemize}
  \tightlist
  \item
    covariates
  \item
    noise variables
  \item
    random effects
  \item
    variance of indidvidual observations vice variance of summary statistics
  \item
    randomization
  \item
    systematic variation of factors/covariates
  \item
    factor identifiability
  \item
    understand issues surrounding multiple comparisons

    \begin{itemize}
    \tightlist
    \item
      Bonferroni correction
    \item
      at least one other method (Tukey?)
    \end{itemize}
  \item
    tradeoffs from replication within groups vice getting more groups
  \item
    compare and contrast methods for designing an experiment when the goal of a study is prediction versus when the goal is statistical inference
  \end{itemize}
\item
  explain the general concept of point estimation and how to account for sampling variability

  \begin{itemize}
  \tightlist
  \item
    definition
  \item
    identify the right point estimate for your response variable of interest
  \item
    estimating uncertainty for point estimates

    \begin{itemize}
    \tightlist
    \item
      normal approximation
    \item
      bootstrap CI
    \item
      others?
    \end{itemize}
  \item
    Types of point estimates:

    \begin{itemize}
    \tightlist
    \item
      means

      \begin{itemize}
      \tightlist
      \item
        Simple effects
      \item
        interaction effects
      \item
        main effects
      \end{itemize}
    \item
      standard deviations/variance components
    \item
      correlation coefficients
    \item
      quantiles/percentiles from distributions
    \item
      probabilities
    \item
      parameters of a distribution
    \item
      model parameters
    \end{itemize}
  \end{itemize}
\item
  describe relevant properties of random variables and probabilities

  \begin{itemize}
  \tightlist
  \item
    Distinguish between mutually exclusive and independent events.
  \item
    Calculate probability for a given scenario, either numerically or using a Venn diagram.
  \item
    Apply the General Addition Rule to solve probability problems.
  \item
    Apply the Rules for Probability Distributions to create a probability distribution for a given scenario.
  \item
    Use the complement of an event to solve probability problems.
  \item
    Apply the Multiplication Rule for Independent Processes to solve probability problems.
  \item
    random variables

    \begin{itemize}
    \tightlist
    \item
      have a defined set of possible outcomes (``sample space'')
    \item
      Discrete vs.~continuous RVs
    \item
      others???
    \end{itemize}
  \item
    probabilities/PDFs

    \begin{itemize}
    \tightlist
    \item
      between 0 and 1 inclusive
    \item
      sum of probability of all possible events is 1
    \item
      \(P(A) + P(A^c) = 1\), where \(A\) is an event and \(A^c\) is the complement of A
    \end{itemize}
  \end{itemize}
\item
  explain the importance of statistical distributions when conducting statistical inference

  \begin{itemize}
  \tightlist
  \item
    normal distribution and approximations plus properties

    \begin{itemize}
    \tightlist
    \item
      robustness
    \item
      generality
    \item
      CLT
    \end{itemize}
  \item
    costs and benefits of using nonparametric approaches
  \end{itemize}
\item
  describe the fundamental inferential techniques of hypothesis testing and confidence intervals as well as compare and contrast their uses and interpretations
\item
  identify a null and alternative for a given problem
  - interpret hypotheses
  - characterize the test statistic under the null
  - explain what a rejection region and be able to identify one
  - define statistical power
  - calculate statistical power for one- and two-sample tests of continuous and binary random variables
  - define statistical confidence\\
  - identify when using a CI and NSHT will result in the same conclusion
  - explain when you can use a confidence interval to test for differences (e.g., comparing a single point estimate to a threshold) and when you can't (e.g., when you have CIs for two different means)
\item
  choose appropriate numerical summaries and graphical displays for a set of data and create these using software

  \begin{itemize}
  \tightlist
  \item
    when to use tables vs.~a picture
  \item
    types of graphical displays

    \begin{itemize}
    \tightlist
    \item
      bar charts
    \item
      pie charts
    \item
      plotting data vice just predictions/conclusions
    \item
      when to include uncertainty bounds
    \item
      five-number summaries
    \item
      means vs.~medians
    \item
      general plotting recommendations
    \item
      use of colors in you plots (discrete vs.~divergent vs.~continuous color scales, gray-scale, color-blind-friendly scales)
    \end{itemize}
  \item
    use of annotations
  \item
    general graphical design philosophy (building a chart to illustrate a conclusion)
  \item
    trade-offs between detail and interpretability
  \item
    not screwing up your axes
  \end{itemize}
\item
  fit statistical models in software and interpret their output

  \begin{itemize}
  \tightlist
  \item
    Which PROCs from SAS? REG, GLM, MIXED, GLIMMIX, others??
  \item
    \texttt{lm()}, \texttt{glm()}, \texttt{anova()} \ldots{}. \texttt{broom}? \texttt{modelr}? \texttt{ciTools}?
  \item
    p-values, point estimates, standard errors, f-statistics, chi-square-statistics, degrees of freedom, SS/MS, residual plots
  \end{itemize}
\item
  connect common statistical methods under the linear model framework

  \begin{itemize}
  \tightlist
  \item
    Write statistical models using matrix representaiton
  \item
    identify models written in matrix representation with their representation in software
  \item
    identify when models written in different notation are the same or different
  \item
    describe when specific models will give you the same results

    \begin{itemize}
    \tightlist
    \item
      ANOVA w/ 2 factors and a t-test or a SLR
    \item
      ANCOVA and MLR
    \item
      random effects vs.~fixed effects
    \item
      split plots vs.~more general mixed models
    \item
      logistic regression w/ categorical factors vice contingency table analysis
    \end{itemize}
  \item
    discuss differences in assumptions associated with ANOVA vice SLR/MLR
  \end{itemize}
\item
  articulate the scope of inferential conclusions in light of the method of data collection, the experimental design used, the assumptions made, and the statistical analysis applied

  \begin{itemize}
  \tightlist
  \item
    limitations due to sampling/sample frame
  \item
    missing data
  \item
    modeling assumptions
  \item
    sampling assumptions
  \item
    requirements for causal inference
  \end{itemize}
\end{itemize}

\hypertarget{topic-level}{%
\section{Topic-level}\label{topic-level}}

\hypertarget{chapter-2---sampling-design-and-exploratory-data-analysis}{%
\subsection{Chapter 2 - Sampling, Design, and Exploratory Data Analysis}\label{chapter-2---sampling-design-and-exploratory-data-analysis}}

\hypertarget{chapter-3---point-estimation}{%
\subsection{Chapter 3 - Point Estimation}\label{chapter-3---point-estimation}}

\hypertarget{chapter-4---accounting-for-uncertainty-in-estimation}{%
\subsection{Chapter 4 - Accounting for Uncertainty in Estimation}\label{chapter-4---accounting-for-uncertainty-in-estimation}}

\hypertarget{chapter-5---inference-via-hypothesis-testing-for-a-proportion-or-mean}{%
\subsection{Chapter 5 - Inference via Hypothesis Testing for a Proportion or Mean}\label{chapter-5---inference-via-hypothesis-testing-for-a-proportion-or-mean}}

\hypertarget{chapter-6---inference-via-confidence-intervals-for-a-proportion-or-mean}{%
\subsection{Chapter 6 - Inference via Confidence Intervals for a Proportion or Mean}\label{chapter-6---inference-via-confidence-intervals-for-a-proportion-or-mean}}

\hypertarget{chapter-7---inference-on-two-categorical-variables}{%
\subsection{Chapter 7 - Inference on Two Categorical Variables}\label{chapter-7---inference-on-two-categorical-variables}}

\hypertarget{chapter-8---inference-for-multiple-means}{%
\subsection{Chapter 8 - Inference for Multiple Means}\label{chapter-8---inference-for-multiple-means}}

\hypertarget{chapter-9---multiway-anova}{%
\subsection{Chapter 9 - Multiway ANOVA}\label{chapter-9---multiway-anova}}

\hypertarget{chapter-10---block-designs}{%
\subsection{Chapter 10 - Block Designs}\label{chapter-10---block-designs}}

\hypertarget{chapter-11---regression}{%
\subsection{Chapter 11 - Regression}\label{chapter-11---regression}}

\hypertarget{chapter-12---the-general-linear-model}{%
\subsection{Chapter 12 - The General Linear Model}\label{chapter-12---the-general-linear-model}}

\hypertarget{chapter-13---mixed-models}{%
\subsection{Chapter 13 - Mixed Models}\label{chapter-13---mixed-models}}

\hypertarget{chapter-14---repeated-measures-and-split-plot-designs}{%
\subsection{Chapter 14 - Repeated Measures and Split Plot Designs}\label{chapter-14---repeated-measures-and-split-plot-designs}}

\hypertarget{chapter-15---logistic-regression-and-generalized-linear-models}{%
\subsection{Chapter 15 - Logistic Regression and Generalized Linear Models}\label{chapter-15---logistic-regression-and-generalized-linear-models}}

\hypertarget{chapter-16---generalized-linear-mixed-models}{%
\subsection{Chapter 16 - Generalized Linear Mixed Models}\label{chapter-16---generalized-linear-mixed-models}}

\hypertarget{from-st512}{%
\section{From ST512}\label{from-st512}}

WE NEED TO ORGANIZE THESE UNDER DIFFERENT CHAPTERS AT SOME POINT
Learning Objectives

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Recognize a completely randomized design with one treatment factor and write the corresponding one-way analysis of variance model, with assumptions
\item
  Estimate treatment means
\item
  Estimate the variance among replicates within a treatment
\item
  Construct the analysis of variance table for a one factor analysis of variance, including computing degrees of freedom, sums of squares, mean squares, and F-ratios
\item
  Interpret results and draw conclusions from a one-factor analysis of variance
\item
  Estimate differences between two treatment means in a one factor analysis of variance
\item
  Test differences between two treatment means in a one factor analysis of variance
\item
  Construct a contrast to estimate or test a linear combination of treatment means
\item
  Estimate the standard error of a linear combination of treatment means
\item
  Make inferences about linear combinations of treatment means, including contrasts.
\item
  Obtain and understand SAS output for linear combinations of treatment means, including contrasts.
\item
  Explain when and why corrections for multiple comparisons are needed
\item
  Know when and how to use Tukey's correction for all pairwise comparisons
\item
  Compute Bonferroni confidence intervals
\item
  Create and interpret orthogonal contrasts.
\item
  Define main effects and interactions
\item
  Write contrasts to estimate main effects and interactions
\item
  Estimate these contrasts and their standard errors
\item
  Compute sums of squares associated with these contrasts
\item
  Test hypotheses about the main effects and interactions.
\item
  Identify and define simple effects.
\item
  Identify and define interaction effects.
\item
  Identify and define main effects.
\item
  Understand when to use simple, interaction, and main effects when drawing inferences in a two-way ANOVA.
\item
  Write the analysis of variance model and SAS code for a completely randomized design with two factors
\item
  Test hypotheses and interpret the analysis of variance for a factorial experiment.
\item
  Explain the appropriate use of correlations and compute the correlation coefficient
\item
  Read and interpret a scatterplot and guess the correlation coefficient by examination of a scatter plot
\item
  Interpret the strength and direction of association indicated by the correlation coefficient and judge when a correlation coefficient provides an appropriate summary of a bivariate relationship
\item
  Test the hypothesis that the correlation coefficient is zero using either a t-test or the Fisher z transformation, Compute confidence intervals using Fisher's z transformation
\item
  Write a statistical model for a straight line regression or a multiple regression and explain what all the terms of the model represent
\item
  Explain the assumptions underlying regression models, evaluate whether the assumptions are met
\item
  Estimate the intercept, slope and variance for a simple linear regression model
\item
  Fit a multiple regression model in SAS and interpret the output, use the coefficient of determination to evaluate model fit
\item
  Use a regression model to predict Y for new values of X
\item
  Estimate the variance and standard error of parameters in regression models, test hypotheses about the parameters, and construct confidence intervals for the parameters.
\item
  Explain the difference between a confidence interval and a prediction interval and know when to use each of them
\item
  Construct a confidence interval for the expected value of Y at a given value of X
\item
  Construct a prediction interval for a new value of Y at a given value of X
\item
  Write a linear model in matrix notation
\item
  Find the expectation and variance of a linear combination of random variables, a'Y
\item
  Set up the expressions to calculate parameter estimates and predicted values using the matrix form of the model
\item
  Estimate standard errors for parameter estimates and predicted values
\item
  Use extra sums of squares to test hypotheses about subsets of parameters
\item
  Construct indicator variables for including categorical regressor variables in a linear model
\item
  Understand how to interpret parameters of a general linear model with indicator variables
\item
  Estimate contrasts of treatment means and their standard errors using the general linear model notation and matrix form of the model
\item
  Compare nested models with a lack of fit test to select a model
\item
  Explain what a covariate is and how they are used
\item
  Explain the assumptions of the analysis of covariance model and determine when these assumptions are met
\item
  Fit an analysis of covariance model in SAS and conduct appropriate tests for treatment effects
\item
  Estimate and interpret treatment means and their standard errors adjusted for covariates using SAS, Construct confidence intervals for adjusted treatment means
\item
  Construct and estimate contrasts of treatment means adjusted for covariates and estimate the standard errors and confidence intervals of such contrasts.
\end{enumerate}

Analysis of variance and design of experiments
Recognize each of the following types of experimental designs and determine when each type would be advantageous.
1. completely randomized design
2. randomized complete block design
3. split plot design
Recognize whether factors should be considered fixed effects or random effects and explain the scope of inference for each case.
Recognize whether factors are crossed or nested.
For all of the designs listed and for experiments with crossed and/or nested fixed factors, random factors, or a combination of fixed and random effects, be able to
1. Write the corresponding analysis of variance model, with assumptions, and define all terms
2. Estimate treatment means and their standard errors
3. Construct the analysis of variance table, including computing degrees of freedom, sums of squares, mean squares, and F-ratios
4. Determine whether the assumptions of the model are satisfied
5. Interpret results and draw conclusions
6. Construct and estimate linear combinations of treatment means and their standard errors
7. Test hypotheses and construct confidence intervals about linear combinations of treatment means
8. Explain when and why corrections for multiple comparisons are needed, know when and how to use Tukey's correction for all pairwise comparisons, compute Bonferroni confidence intervals
9. Create and interpret orthogonal contrasts.
10. Define and interpret main effects, simple effects and interactions
11. Use a table of expected mean squares to estimate variance components and determine appropriate F-statistics for testing effects in the analysis of variance
12. Interpret variance components and estimate and interpret the intraclass correlation coefficient.
Regression and correlation
Explain the appropriate use of correlations and compute the correlation coefficient, read and interpret a scatterplot and guess the correlation coefficient by examination of a scatter plot, test the hypothesis that the correlation coefficient is zero using either a t-test or the Fisher z transformation, compute confidence intervals using Fisher's z transformation
You should be able to do the following for fitting models to describe the relationships of one or several variables to a response variable. The regressor variables may be continuous or categorical or a mix of the two (e.g., analysis of covariance models)
1. Write a general linear model, including assumptions, in standard or matrix notation, and explain what all the terms and assumptions represent. Be able to handle models that contain interaction terms, polynomial terms, and dummy variables.
2. Evaluate whether the model assumptions are met
3. Fit a general linear model in SAS and interpret the output
4. Work with the general linear model in matrix form, including finding the expectation and variance of a linear combination of regression coefficients or treatment means
5. Test hypotheses and construct confidence intervals for linear combinations of the parameters
6. Construct and interpret a confidence interval for the expected value of Y at a given value of X
7. Construct and interpret a prediction interval for a new value of Y at a given value of X
8. Use extra sums of squares to test hypotheses about subsets of parameters.
9. Explain what a covariate is and how covariates are used

\hypertarget{for-point-estimates-chapter}{%
\section{For Point Estimates Chapter}\label{for-point-estimates-chapter}}

\begin{itemize}
\item
  Definitions for Mean, Median, Quantile, Percentile
\item
  Explain uses for the above
\item
  Identify the correct point estimate to use for a given test
\item
  Define Systematic Random Sample and Convenience Sample
\item
  Explain strengths and weaknesses of each
\item
  Identify conditions when Systematic and Convenience Sampling may not provide representitive samples
\end{itemize}

\hypertarget{notation}{%
\chapter{Appendix - Notation}\label{notation}}

\hypertarget{standard-notation}{%
\section{Standard notation}\label{standard-notation}}

Vectors of variables are denoted with Roman letters, such as \(x\) and \(Y\). Capital letters denote random variables while lower case letters denote fixed variables. Note that these vectors may be of length 1 depending on context. Bolded values (\textbf{\(x\)}) denote matrices, and in the case of \textbf{\(Y\)}, possibly single-column matrices.

Unknown parameters are denoted with Greek letters, with boldface font indicating matrices.

In most models, \(Y\) will denote the univariate response, \textbf{\(x\)} will describe a matrix of predictor variables, and \(E\) a vector of random errors. The Greek letter \(\beta\) will be commonly used for regression parameters (either with subscripts for each values as in \(\beta_0 + \beta_1 X_1\) or as a vector (as in \(X\beta\)). The letters \(i, j, k,\) and \(l\) will be most commonly used as subscripts or indices. \(N\) will typically denote a sample size (not a random vector), with subscripted versions (\(n_i\)) describing the number of observations in a group, and \(p\) describing the number of parameters in a model beyond the intercept.

We may therefore describe a simple linear regresion model as:

\[Y = x\beta + E\]

In this model, \(Y\) is a \(N\times 1\) random vector, \textbf{\(x\)} is a \(N\times (p + 1)\) matrix of fixed values, and \(E\) is a \(N \times 1\) vector.

\(\pi\) is typically used to describe probability parameters, as in Bernoulli or binomial random variables.

\hypertarget{mixed-models}{%
\section{Mixed models}\label{mixed-models}}

Still need to add something for this

\hypertarget{effects-model-representation}{%
\section{Effects model representation}\label{effects-model-representation}}

In the effects formulation of ANOVA models, additional greek letters (\(\alpha\), \(\gamma\), etc.) will appear as parameter effects, as will \(\mu\), which will typically represent the grand mean. Group-specfic means will be denoted via subscripts: \(\mu_{ij}\). When using this representation, it is convenient to describe a single observation as \(Y_{ijk}\), which is the \(k\)th observation from the group with with the \(i\)th level of the first factor and the \(j\)th level of the second factor. In the main effects version of this model, we have:

\[Y_{ijk} = \mu + \alpha_i + \gamma_j + E_{ijk}\]

We can therefore estimate \(\mu_{ij}\) as \(\hat \mu_{ij} = \frac{1}{n}\sum_{k = 1}^n Y_{ijk} = \bar{Y}_{ij\cdot}\). This ``dot'' notation can be extended to any subscript and indicates summing over the index that has been replaced by the dot. Further note that the ``hat'' over a paremeter value denotes the estimator for that parameter value, and the ``bar'' indicates an average. These features are used generally throughout this book.

\hypertarget{estimators-vs.-estimates}{%
\section{Estimators vs.~Estimates}\label{estimators-vs.-estimates}}

If we want to get pedantic, we can differentiate between estimates and estimators in our notation. Estimators are functions of random variables used to estimate parameters. Estimates are realized values of estimators. To differentiate these, we use Roman letters with hats to represent estimators (\(\hat B = (x'x )^{-1}x'Y\)) and Greek letters with hats to represent estimates (\(\hat \beta = 1.52\)).

  \bibliography{book.bib,packages.bib}

\end{document}
